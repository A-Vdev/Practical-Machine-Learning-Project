---
title: "Machine-Learning-Project"
author: "Abhijeet"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Synopsis

This Report is a course project of the Practical Machine Learning Course of [Data Science Specialization](https://www.coursera.org/specializations/jhu-data-science) by Johns Hopkins University on Coursera.
Aim of this project is to choose and apply machine learning algorithm to the 20 test cases in the course.The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har

**Background**
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, the goal is to use the data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.
More information is available from the website here: http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har

## Loading the Data
- Loading the `train` and `test` data.
```{r}
trainingData<-read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"),header = TRUE)
testingData<-read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"),header = TRUE)
```

### Exploring the Data
```{r}
str(trainingData)
```
- The set has 19622 observation and 160 variables. Many columns seems to contain numerous empty `""` and `NA` elements. Before analysis, it will be wise to clear the data for easier analysis.

## Data Cleaning

- Removing columns with more than 90% NA's or empty elements to clean the data for fitting the model.
```{r}
#training Data 
EmptyCols<-which(colSums(is.na(trainingData)| trainingData=="")>0.9*dim(trainingData)[1])
trainingData<-trainingData[,-EmptyCols]
# removing unwanted columns
trainingData<-trainingData[,-c(1:7)]

# testing Data
EmptyCols<-which(colSums(is.na(testingData)| testingData=="")>0.9*dim(testingData)[1])
testingData<-testingData[,-EmptyCols]
# removing unwanted columns
testingData<-testingData[,-c(1:7)]
```
```{r}
dim(trainingData)
dim(testingData)
```

## Data Splitting
- Preparing the data for training and testing by splitting 70% as `training` and 30% as `testing` dataset.
```{r}
suppressMessages(library(caret)); 

inTrain <- createDataPartition(trainingData$classe,
                              p=0.7, list=FALSE)
# Training Data
training <- trainingData[inTrain,]
# Test Data
testing <- trainingData[-inTrain,]
dim(training)
```
## Model Selection

1. To predict the outcome, we will use three different methods to model regression.
2. The **Random Forest Model** `rf`, **Gradient Boosting Model** `gbm` and **Decision Tree Model** `rpart` algorithms are used for accuracy comparison.
3. **k-fold cross validation** method is used to reduce risk of overfitting.Number of folds are chosen to be `5` to reduce the training time.

### Random Forests Model
- fitting the training data to Random Forest Model
```{r}
set.seed(33833)
# cross validation 
train.control<-trainControl(method = "cv",number=5)
# Random Forest
model_rf<-train(classe~.,method="rf",data=training,trControl =train.control,verbose=FALSE)
```

**Validating the model** on test Data
```{r}
RF_predict<-predict(model_rf,newdata=testing);
RF_cm<- confusionMatrix(RF_predict,as.factor(testing$classe))
RF_cm
# model accuracy
RF_cm$overall['Accuracy']
```

### Gradient Boosting Model
- fitting the training data to Gradient Boosting Model
```{r}
model_gbm<-train(classe~.,method="gbm",data=training,trControl = train.control,verbose=FALSE)
```

**Validating the model accuracy** on test Data
```{r}
gbm_predict<-predict(model_gbm,newdata=testing);
gbm_cm<- confusionMatrix(as.factor(testing$classe),gbm_predict)
gbm_cm
# model accuracy
gbm_cm$overall['Accuracy']
```
### Decision Tree Model
```{r}
model_rpart<-train(classe~., method="rpart", data=training,trControl = train.control)
```
- plotting the **Decision Tree**.
```{r}
suppressMessages(library(rattle))
fancyRpartPlot(model_rpart$finalModel)
```

**Validating the model accuracy** on test Data.
```{r}
rpart_predict<-predict(model_rpart,testing)
rpart_cm<- confusionMatrix(as.factor(testing$classe),rpart_predict)
# model accuracy
rpart_cm$overall['Accuracy']
```

### Comparison of results

- Accuracies:
```{r}
print(paste0("Random Forest model accuracy: ",round(RF_cm$overall['Accuracy'],3)))
print(paste0("Gradient Boosting Model accuracy: ",round(gbm_cm$overall['Accuracy'],3)))
print(paste0("Decision Tree Model accuracy: ",round(rpart_cm$overall['Accuracy'],3)))
```
- The accuracy obtained form the Random Forest Model `rf` prediction  is **0.995** which better than the  Gradient Boosting Model `gbm` and Decision Tree Model `rpart` prediction with the accuracy of **0.968** and **0.501** respectively.

## Implimenting the best model

1. After comparing the accuracy rate of three models, The accuracy obtained from 'Random Forest model` is best.
2. Implementing the Random Forest model to the `testData` data.
```{r}
validation<-predict(model_rf,testingData)
validation
```

